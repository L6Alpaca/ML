1.随机森林 由 随机的 有放回的 取样中，随机选择部分特征，共同构成的、大量的决策树组成
2.一种基于决策树的集成学习(Ensemble learning)算法——大量的结论，取占比最高的作为最终结论（集思广益）——通过训练学习出多个估计器，当需要预测时通过结合器将多个估计器的结果整合起来当作最后的结果输出。

3.决策树 & 随机森林
  随机森林
     优点：
         每个决策树无依据，纯随机，对数据敏感度不高，但由于数量大，性能更稳定，抗噪能力好
         每次选择部分样本，一定程度避免过拟合
     缺点：
         参数较复杂；
         模型训练和预测都比较慢。
  决策树只有一颗，对数据较为敏感，容易产生误差，导致泛化性能降低

4.对于随机森林的bagging思想（相当于Bootstraping and Aggregating，Bootstraping（自主取样法）——有放回的随机抽样（选择训练/测试集时也有用到，有一部分总是选不到），Aggregating——合并）

5.使用场景
分类问题：随机森林可以用于分类问题，如图像分类、文本分类、情感分析等。
回归问题：随机森林也可以用于回归问题，如房价预测、股票价格预测等。
特征选择：随机森林可以用于特征选择，即从众多特征中选择最重要的特征。